{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcxVoR1ZtWTI/Ga9Q8z0Fj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmbernardo7520112/APIs-Serverless-dio-lmb/blob/master/audio_cd_cs_simplified_version_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget  # If you haven't already installed wget\n",
        "\n",
        "import os\n",
        "\n",
        "def download_and_extract_dataset():\n",
        "    \"\"\"Downloads and extracts the Mini Speech Commands dataset.\"\"\"\n",
        "    print(\"Baixando o dataset Mini Speech Commands...\")\n",
        "    !wget http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\n",
        "    print(\"Dataset baixado com sucesso!\")\n",
        "\n",
        "    print(\"Extraindo o dataset Mini Speech Commands...\")\n",
        "    !unzip -q mini_speech_commands.zip\n",
        "    print(\"Dataset extraído com sucesso!\")\n",
        "\n",
        "# Execute the download and extraction\n",
        "download_and_extract_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Yj6IVdqdsZdq",
        "outputId": "75e7cae1-a739-4c6c-caae-458009132466"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=9142d5513533ccdb60553ee4cb6b2b854c19af4222a3df7d07e464f867fc6810\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Baixando o dataset Mini Speech Commands...\n",
            "--2024-11-18 21:14:50--  http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.187.207, 64.233.188.207, 64.233.189.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.187.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 182082353 (174M) [application/zip]\n",
            "Saving to: ‘mini_speech_commands.zip’\n",
            "\n",
            "mini_speech_command 100%[===================>] 173.65M  29.1MB/s    in 6.6s    \n",
            "\n",
            "2024-11-18 21:14:57 (26.2 MB/s) - ‘mini_speech_commands.zip’ saved [182082353/182082353]\n",
            "\n",
            "Dataset baixado com sucesso!\n",
            "Extraindo o dataset Mini Speech Commands...\n",
            "Dataset extraído com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Configurações iniciais\n",
        "COMMANDS = ['down', 'go', 'left', 'no', 'right', 'stop', 'up', 'yes']\n",
        "SAMPLE_RATE = 16000  # Taxa de amostragem\n",
        "MAX_DURATION = 1  # Duração máxima em segundos\n",
        "\n",
        "# Função para carregar áudio com fallback\n",
        "def load_audio(file_path, sample_rate, max_duration, fallback_file=None):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Arquivo não encontrado: {file_path}\")\n",
        "        if fallback_file and os.path.exists(fallback_file):\n",
        "            print(f\"Usando arquivo substituto: {fallback_file}\")\n",
        "            file_path = fallback_file\n",
        "        else:\n",
        "            return None\n",
        "    try:\n",
        "        audio, sr = librosa.load(file_path, sr=sample_rate, mono=True, duration=max_duration)\n",
        "        return audio, sr\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar o arquivo {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Função para extrair características emocionais\n",
        "def extract_emotional_features(file_path):\n",
        "    fallback_files = glob.glob(\"mini_speech_commands/stop/*.wav\")  # Arquivos substitutos\n",
        "    fallback_file = fallback_files[0] if fallback_files else None\n",
        "    data = load_audio(file_path, SAMPLE_RATE, MAX_DURATION, fallback_file)\n",
        "    if data is None:\n",
        "        return None\n",
        "\n",
        "    audio, sr = data\n",
        "    try:\n",
        "        features = {\n",
        "            'pitch_mean': np.mean(librosa.yin(audio, fmin=100, fmax=800, sr=sr)),\n",
        "            'pitch_std': np.std(librosa.yin(audio, fmin=100, fmax=800, sr=sr)),\n",
        "            'rms_energy': np.mean(librosa.feature.rms(y=audio)[0]),\n",
        "            'zero_crossing_rate': np.mean(librosa.feature.zero_crossing_rate(audio)),\n",
        "            'spectral_centroid': np.mean(librosa.feature.spectral_centroid(y=audio, sr=sr)[0]),\n",
        "            'spectral_bandwidth': np.mean(librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]),\n",
        "            'spectral_rolloff': np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]),\n",
        "            'mfccs': librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "        }\n",
        "        return features\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao extrair características de {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Função para extrair espectrograma mel\n",
        "def extract_mel_spectrogram(file_path):\n",
        "    fallback_files = glob.glob(\"mini_speech_commands/stop/*.wav\")\n",
        "    fallback_file = fallback_files[0] if fallback_files else None\n",
        "    data = load_audio(file_path, SAMPLE_RATE, MAX_DURATION, fallback_file)\n",
        "    if data is None:\n",
        "        return None\n",
        "\n",
        "    audio, sr = data\n",
        "    try:\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)\n",
        "        mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "        return mel_spectrogram_db\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao extrair espectrograma de {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Função para criar o modelo de rede neural\n",
        "def create_emotional_command_model(input_shape):\n",
        "    input_spec = layers.Input(shape=input_shape, name='spectogram_input')\n",
        "    input_emotion = layers.Input(shape=(4,), name='emotional_features')\n",
        "\n",
        "    x = layers.Conv2D(32, 3, activation='relu')(input_spec)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    combined = layers.Concatenate()([x, input_emotion])\n",
        "    x = layers.Dense(128, activation='relu')(combined)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(len(COMMANDS), activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=[input_spec, input_emotion], outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Função principal de treinamento\n",
        "def train_emotional_command_recognition():\n",
        "    spectrograms, emotional_features, labels = [], [], []\n",
        "    fallback_files = glob.glob(\"mini_speech_commands/stop/*.wav\")\n",
        "    fallback_file = fallback_files[0] if fallback_files else None\n",
        "\n",
        "    for command in COMMANDS:\n",
        "        path = f\"mini_speech_commands/{command}\"\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"Diretório não encontrado: {path}\")\n",
        "            continue\n",
        "        for file in tqdm(glob.glob(os.path.join(path, \"*.wav\"))):\n",
        "            features = extract_emotional_features(file)\n",
        "            if features is None:\n",
        "                continue\n",
        "            spectrogram = extract_mel_spectrogram(file)\n",
        "            if spectrogram is None:\n",
        "                continue\n",
        "            spectrograms.append(spectrogram)\n",
        "            emotional_features.append([features['pitch_mean'], features['pitch_std'], features['rms_energy'], features['zero_crossing_rate']])\n",
        "            labels.append(COMMANDS.index(command))\n",
        "\n",
        "    if not spectrograms:\n",
        "        raise ValueError(\"Nenhum espectrograma foi extraído.\")\n",
        "\n",
        "    max_rows = max(spec.shape[0] for spec in spectrograms)\n",
        "    max_cols = max(spec.shape[1] for spec in spectrograms)\n",
        "\n",
        "    spectrograms = np.array([  # Pad spectrograms to the maximum size\n",
        "        np.pad(spec, ((0, max_rows - spec.shape[0]), (0, max_cols - spec.shape[1])), mode='constant')\n",
        "        for spec in spectrograms\n",
        "    ])[..., np.newaxis]\n",
        "    emotional_features = np.array(emotional_features)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    indices = np.random.permutation(len(spectrograms))\n",
        "    training_idx = indices[:int(0.8 * len(indices))]\n",
        "    test_idx = indices[int(0.8 * len(indices)):]\n",
        "\n",
        "    # Create and compile the model\n",
        "    model = create_emotional_command_model(spectrograms[0].shape)\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # EarlyStopping and ReduceLROnPlateau callback setup\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',  # Monitor the loss for early stopping\n",
        "            patience=5,  # Tuning patience to avoid stopping too early\n",
        "            restore_best_weights=True,  # Restore the best weights based on val_loss\n",
        "            mode='min'  # 'min' for monitoring loss, 'max' for accuracy\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',  # Reduce learning rate based on validation loss\n",
        "            factor=0.5,  # Reduce LR by a factor of 0.5\n",
        "            patience=3,  # Number of epochs to wait before reducing LR\n",
        "            mode='min'  # 'min' for loss\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        [spectrograms[training_idx], emotional_features[training_idx]],\n",
        "        labels[training_idx],\n",
        "        validation_data=(\n",
        "            [spectrograms[test_idx], emotional_features[test_idx]],\n",
        "            labels[test_idx]\n",
        "        ),\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Execução\n",
        "if __name__ == \"__main__\":\n",
        "    model = train_emotional_command_recognition()\n",
        "    test_file = \"mini_speech_commands/stop/0a7c2a8d_nohash_0.wav\"\n",
        "    features = extract_emotional_features(test_file)\n",
        "    print(features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sirsb10gjzcP",
        "outputId": "66626726-4b49-4471-a44b-837903e836e7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:51<00:00, 19.30it/s]\n",
            "100%|██████████| 1000/1000 [00:55<00:00, 18.13it/s]\n",
            "100%|██████████| 1000/1000 [00:57<00:00, 17.54it/s]\n",
            "100%|██████████| 1000/1000 [00:55<00:00, 17.96it/s]\n",
            "100%|██████████| 1000/1000 [00:53<00:00, 18.74it/s]\n",
            "100%|██████████| 1000/1000 [00:52<00:00, 19.15it/s]\n",
            "100%|██████████| 1000/1000 [00:53<00:00, 18.65it/s]\n",
            "100%|██████████| 1000/1000 [00:52<00:00, 19.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 234ms/step - accuracy: 0.2181 - loss: 3.6773 - val_accuracy: 0.4400 - val_loss: 1.5441 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 251ms/step - accuracy: 0.3585 - loss: 1.6718 - val_accuracy: 0.4850 - val_loss: 1.4134 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 236ms/step - accuracy: 0.4290 - loss: 1.4762 - val_accuracy: 0.4700 - val_loss: 1.3477 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 234ms/step - accuracy: 0.4661 - loss: 1.3782 - val_accuracy: 0.1669 - val_loss: 3.5415 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 238ms/step - accuracy: 0.4969 - loss: 1.2721 - val_accuracy: 0.3738 - val_loss: 1.9973 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 232ms/step - accuracy: 0.5193 - loss: 1.1818 - val_accuracy: 0.6087 - val_loss: 1.0990 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 243ms/step - accuracy: 0.5541 - loss: 1.1135 - val_accuracy: 0.2844 - val_loss: 3.8907 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 237ms/step - accuracy: 0.5853 - loss: 1.0249 - val_accuracy: 0.5631 - val_loss: 1.7025 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 234ms/step - accuracy: 0.6235 - loss: 0.9362 - val_accuracy: 0.7513 - val_loss: 0.7794 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 243ms/step - accuracy: 0.6472 - loss: 0.8546 - val_accuracy: 0.6762 - val_loss: 0.9647 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 238ms/step - accuracy: 0.6864 - loss: 0.8011 - val_accuracy: 0.5275 - val_loss: 1.4635 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 237ms/step - accuracy: 0.7161 - loss: 0.7245 - val_accuracy: 0.7719 - val_loss: 0.6924 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 230ms/step - accuracy: 0.7207 - loss: 0.7017 - val_accuracy: 0.6206 - val_loss: 1.6638 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 234ms/step - accuracy: 0.7419 - loss: 0.6648 - val_accuracy: 0.7694 - val_loss: 0.7245 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 245ms/step - accuracy: 0.7801 - loss: 0.5680 - val_accuracy: 0.8056 - val_loss: 0.6015 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 240ms/step - accuracy: 0.7830 - loss: 0.5554 - val_accuracy: 0.7125 - val_loss: 0.8957 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 246ms/step - accuracy: 0.7969 - loss: 0.5234 - val_accuracy: 0.6969 - val_loss: 1.1313 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 241ms/step - accuracy: 0.8159 - loss: 0.4804 - val_accuracy: 0.7962 - val_loss: 0.6130 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 244ms/step - accuracy: 0.8197 - loss: 0.4450 - val_accuracy: 0.8675 - val_loss: 0.4040 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 245ms/step - accuracy: 0.8419 - loss: 0.3983 - val_accuracy: 0.8644 - val_loss: 0.4837 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 243ms/step - accuracy: 0.8534 - loss: 0.3868 - val_accuracy: 0.8587 - val_loss: 0.5419 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 260ms/step - accuracy: 0.8761 - loss: 0.3087 - val_accuracy: 0.8631 - val_loss: 0.4464 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 238ms/step - accuracy: 0.8734 - loss: 0.3045 - val_accuracy: 0.8725 - val_loss: 0.4840 - learning_rate: 2.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 241ms/step - accuracy: 0.8915 - loss: 0.2780 - val_accuracy: 0.8850 - val_loss: 0.3823 - learning_rate: 2.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 248ms/step - accuracy: 0.8943 - loss: 0.2739 - val_accuracy: 0.8844 - val_loss: 0.4114 - learning_rate: 2.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 239ms/step - accuracy: 0.8926 - loss: 0.2714 - val_accuracy: 0.8919 - val_loss: 0.4218 - learning_rate: 2.5000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 249ms/step - accuracy: 0.9021 - loss: 0.2416 - val_accuracy: 0.8444 - val_loss: 0.7155 - learning_rate: 2.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 239ms/step - accuracy: 0.8928 - loss: 0.2690 - val_accuracy: 0.8913 - val_loss: 0.3901 - learning_rate: 1.2500e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 251ms/step - accuracy: 0.8992 - loss: 0.2393 - val_accuracy: 0.8894 - val_loss: 0.3866 - learning_rate: 1.2500e-04\n",
            "Arquivo não encontrado: mini_speech_commands/stop/0a7c2a8d_nohash_0.wav\n",
            "Usando arquivo substituto: mini_speech_commands/stop/24befdb3_nohash_3.wav\n",
            "{'pitch_mean': 235.66168273018644, 'pitch_std': 166.42209991030094, 'rms_energy': 0.036354795, 'zero_crossing_rate': 0.1298675537109375, 'spectral_centroid': 1774.6510397412358, 'spectral_bandwidth': 1662.8038044055616, 'spectral_rolloff': 3365.234375, 'mfccs': array([[-5.08440826e+02, -4.82587036e+02, -4.74714355e+02,\n",
            "        -4.69221008e+02, -4.77429077e+02, -4.73426636e+02,\n",
            "        -3.97125977e+02, -3.15152740e+02, -2.75789062e+02,\n",
            "        -2.74758728e+02, -2.85448578e+02, -1.81706024e+02,\n",
            "        -1.03101357e+02, -1.03704796e+02, -1.22145996e+02,\n",
            "        -1.36795990e+02, -1.78504883e+02, -2.63049591e+02,\n",
            "        -3.59010651e+02, -4.03241547e+02, -4.36485657e+02,\n",
            "        -4.59550446e+02, -4.56122375e+02, -4.59503265e+02,\n",
            "        -4.77582184e+02, -4.79509796e+02, -4.77218079e+02,\n",
            "        -4.60084045e+02, -4.28123718e+02, -4.30112579e+02,\n",
            "        -4.51111328e+02, -4.87595856e+02],\n",
            "       [ 9.76012802e+01,  1.06488983e+02,  1.03932358e+02,\n",
            "         9.72235718e+01,  9.45832825e+01,  8.90373993e+01,\n",
            "         3.03374233e+01, -1.92833023e+01, -3.82951546e+01,\n",
            "        -3.85714417e+01, -2.37524567e+01,  8.28942719e+01,\n",
            "         1.36825043e+02,  1.86813049e+02,  2.07377136e+02,\n",
            "         1.99708542e+02,  1.99974686e+02,  2.03345673e+02,\n",
            "         1.46175934e+02,  9.77062683e+01,  9.20919647e+01,\n",
            "         9.43227005e+01,  9.53114471e+01,  1.03258102e+02,\n",
            "         1.12162384e+02,  1.17810181e+02,  1.19106689e+02,\n",
            "         1.13167664e+02,  1.11742134e+02,  1.13049606e+02,\n",
            "         1.04279922e+02,  9.77525482e+01],\n",
            "       [ 1.86202946e+01,  1.41154919e+01,  1.44035463e+01,\n",
            "         1.24839420e+01,  1.43867702e+01,  8.13080406e+00,\n",
            "         1.89692955e+01,  4.45105667e+01,  6.32584381e+01,\n",
            "         7.26195221e+01,  5.13046722e+01, -2.64769363e+00,\n",
            "        -2.76838837e+01, -3.92529297e+01, -2.97881126e+01,\n",
            "        -2.68393631e+01, -2.06353073e+01,  2.51923847e+00,\n",
            "         2.48233738e+01,  1.45722370e+01,  1.62723217e+01,\n",
            "         2.37699699e+01,  2.87455330e+01,  2.55136585e+01,\n",
            "         1.89856606e+01,  1.57574196e+01,  2.08456364e+01,\n",
            "         1.37135143e+01, -1.86107302e+00,  7.64948845e+00,\n",
            "         1.83846130e+01,  2.15953751e+01],\n",
            "       [ 5.25615072e+00,  1.12444687e+01,  1.31580658e+01,\n",
            "         1.05630178e+01,  1.48156452e+01,  2.23224792e+01,\n",
            "         2.89310150e+01,  2.98438568e+01,  3.18605003e+01,\n",
            "         3.47326813e+01,  3.77775345e+01,  3.43184624e+01,\n",
            "         9.77078342e+00, -1.01341772e+01, -1.84214859e+01,\n",
            "        -1.90564728e+01, -1.02001286e+01, -1.53112054e+00,\n",
            "         5.98907089e+00,  7.79912615e+00,  1.63280029e+01,\n",
            "         1.81036148e+01,  8.88012409e+00,  9.08957386e+00,\n",
            "         9.36508942e+00,  5.61268473e+00,  4.89822865e+00,\n",
            "         5.05276859e-01, -4.15439278e-01,  2.91141272e+00,\n",
            "         8.31333542e+00,  1.35745049e+01],\n",
            "       [ 3.98275805e+00,  4.50860071e+00,  4.58174515e+00,\n",
            "        -1.34821570e+00,  5.26407242e+00,  8.73345757e+00,\n",
            "        -2.15865974e+01, -2.75895195e+01, -3.32292633e+01,\n",
            "        -3.06511536e+01, -2.75855751e+01, -2.45555401e+01,\n",
            "        -2.14609070e+01, -2.33608322e+01, -3.82573090e+01,\n",
            "        -4.88114853e+01, -4.41243362e+01, -3.44403687e+01,\n",
            "        -8.47648716e+00, -2.45762444e+00,  5.65895557e-01,\n",
            "         5.60995293e+00,  1.14386454e+01,  1.74139652e+01,\n",
            "         1.34411221e+01,  5.82871151e+00,  3.16580081e+00,\n",
            "        -1.05522096e+00, -9.73157692e+00, -8.31509209e+00,\n",
            "         6.66471577e+00,  1.94311676e+01],\n",
            "       [ 1.02254117e+00, -1.01303616e+01, -1.49431362e+01,\n",
            "        -1.67019348e+01, -1.78246689e+01, -1.32969265e+01,\n",
            "         2.63227615e+01,  3.75630875e+01,  3.52315865e+01,\n",
            "         3.47115555e+01,  2.22303200e+01, -5.02546310e+00,\n",
            "        -4.99024916e+00, -1.16216125e+01, -1.98309879e+01,\n",
            "        -1.96644478e+01, -1.68826256e+01, -1.36329422e+01,\n",
            "        -8.05377960e+00, -1.82254505e+01, -2.60956593e+01,\n",
            "        -2.96870899e+01, -2.75795422e+01, -1.98205948e+01,\n",
            "        -1.87862206e+01, -2.47755318e+01, -2.48401680e+01,\n",
            "        -2.45849171e+01, -1.40075016e+01, -6.18015575e+00,\n",
            "        -3.32592583e+00, -4.54870605e+00],\n",
            "       [ 1.98549724e+00, -6.46327209e+00, -1.07588615e+01,\n",
            "        -1.36472082e+01, -1.39255257e+01, -2.38430882e+01,\n",
            "        -4.41049805e+01, -3.45445442e+01, -2.77483330e+01,\n",
            "        -1.68764992e+01, -7.52388191e+00, -7.58686352e+00,\n",
            "        -8.78052330e+00, -8.68460846e+00,  2.48548698e+00,\n",
            "         2.63822460e+00, -3.61191273e+00, -5.97915125e+00,\n",
            "        -3.03126526e+00, -1.13282290e+01, -1.38092756e+01,\n",
            "        -1.29658003e+01, -1.38922806e+01, -2.04908466e+01,\n",
            "        -2.91438560e+01, -2.97210350e+01, -2.43669968e+01,\n",
            "        -1.40011683e+01, -1.98095775e+00, -2.53524065e+00,\n",
            "        -6.79037857e+00, -8.45409584e+00],\n",
            "       [-4.38512039e+00, -7.07082415e+00, -9.61602974e+00,\n",
            "        -6.31938076e+00, -7.14527702e+00, -1.62889538e+01,\n",
            "        -2.33159485e+01, -2.95421906e+01, -2.62554626e+01,\n",
            "        -2.11667500e+01, -2.50849190e+01, -3.94101868e+01,\n",
            "        -3.55228729e+01, -1.90413628e+01, -5.31462002e+00,\n",
            "         4.87613821e+00,  1.42153764e+00, -6.08984852e+00,\n",
            "        -4.48165274e+00, -5.86019611e+00, -4.51471949e+00,\n",
            "        -4.25538635e+00, -8.27218914e+00, -1.05897369e+01,\n",
            "        -9.69165611e+00, -9.94157982e+00, -7.37132740e+00,\n",
            "        -6.94529200e+00,  1.80574465e+00,  5.08003473e+00,\n",
            "         1.57919431e+00,  6.65613890e-01],\n",
            "       [-5.81784868e+00, -6.01356983e+00, -3.86385727e+00,\n",
            "        -2.08623695e+00, -1.16623437e+00,  1.26300516e+01,\n",
            "         1.84083481e+01,  6.37442827e-01,  8.60008538e-01,\n",
            "         2.88457513e-01, -1.08412790e+01, -1.52111168e+01,\n",
            "        -1.87655945e+01, -2.87257023e+01, -2.89451084e+01,\n",
            "        -2.75328693e+01, -2.65708694e+01, -1.43550081e+01,\n",
            "        -1.41649876e+01, -1.96117706e+01, -1.72514534e+01,\n",
            "        -9.93482780e+00, -1.04980907e+01, -1.12160206e+01,\n",
            "        -1.91815019e+00,  8.17984772e+00,  7.04754591e+00,\n",
            "         9.89488959e-01,  1.51097059e+00, -7.53189921e-01,\n",
            "         1.06888115e-02,  4.41204357e+00],\n",
            "       [-8.88874817e+00, -1.40956192e+01, -1.53272319e+00,\n",
            "         7.47305822e+00,  8.17159653e+00,  3.72464204e+00,\n",
            "        -3.98028183e+00, -1.26908088e+00, -5.79093742e+00,\n",
            "        -1.51382532e+01, -5.39453745e+00,  1.57162800e+01,\n",
            "         1.31184168e+01,  6.09197140e+00, -4.29071331e+00,\n",
            "        -8.85967827e+00, -1.38842478e+01, -1.66156540e+01,\n",
            "        -1.08332863e+01, -1.44471633e+00, -7.57060194e+00,\n",
            "        -1.15761681e+01, -5.71328354e+00,  2.23560143e+00,\n",
            "         9.66318607e+00,  9.91657162e+00,  7.82821369e+00,\n",
            "         8.93953896e+00,  6.25937700e+00, -2.09906387e+00,\n",
            "        -8.57972145e+00, -7.10023403e+00],\n",
            "       [-1.35725937e+01, -1.57019711e+01, -1.25270176e+01,\n",
            "        -4.75145054e+00, -3.45591235e+00, -9.47513008e+00,\n",
            "        -1.38256245e+01, -1.71834793e+01, -2.46633148e+01,\n",
            "        -2.77684708e+01, -1.60826492e+01, -8.63278675e+00,\n",
            "        -4.82617944e-01, -3.99563581e-01, -9.64600682e-01,\n",
            "        -4.88026714e+00, -8.07720947e+00, -8.33418655e+00,\n",
            "        -1.46763134e+00,  1.67967319e+01,  7.29763556e+00,\n",
            "        -5.95099449e+00, -1.29880915e+01, -5.77058172e+00,\n",
            "         3.67450190e+00,  5.01323318e+00,  5.14332867e+00,\n",
            "         2.79565811e+00, -4.28923416e+00, -8.25091171e+00,\n",
            "        -9.38514996e+00, -1.20381861e+01],\n",
            "       [-1.47417915e+00,  1.71812010e+00, -7.28599310e+00,\n",
            "        -8.06721783e+00, -3.68551731e+00, -3.43238616e+00,\n",
            "         6.02867270e+00,  9.18318331e-01, -4.46010768e-01,\n",
            "         5.03862286e+00, -2.57654488e-01,  6.80992222e+00,\n",
            "         1.71367760e+01,  2.09227867e+01,  2.18522053e+01,\n",
            "         2.36109486e+01,  1.23953066e+01, -2.41301346e+00,\n",
            "         2.26026917e+00,  1.61918030e+01,  9.13613510e+00,\n",
            "         1.18077695e+00,  2.43207359e+00,  5.95743752e+00,\n",
            "         1.53789973e+00,  2.82086945e+00,  9.74677467e+00,\n",
            "         1.34648830e-01, -1.03739729e+01, -1.47894402e+01,\n",
            "        -5.39233875e+00, -1.06014991e+00],\n",
            "       [ 6.83140039e+00,  4.65308189e+00,  7.64789581e-02,\n",
            "        -9.25484776e-01, -4.73603678e+00, -1.49720573e+01,\n",
            "        -2.38760281e+01, -1.58615971e+01, -1.93176479e+01,\n",
            "        -2.61981316e+01, -3.35426254e+01, -1.57132759e+01,\n",
            "        -2.20303345e+01, -2.35068512e+01, -1.71040001e+01,\n",
            "        -1.40028019e+01, -1.16207867e+01, -1.16725273e+01,\n",
            "        -1.41885967e+01, -9.40320396e+00, -6.68408442e+00,\n",
            "        -1.01116867e+01, -1.09856691e+01, -1.08260422e+01,\n",
            "        -5.45000935e+00, -6.81406975e-01,  1.88947964e+00,\n",
            "        -6.29877949e+00, -1.14645834e+01, -1.48264198e+01,\n",
            "        -1.83137970e+01, -1.35431213e+01]], dtype=float32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras import layers, models\n",
        "import random  # Added import for random file selection\n",
        "\n",
        "# Configurações iniciais\n",
        "COMMANDS = ['down', 'go', 'left', 'no', 'right', 'stop', 'up', 'yes']\n",
        "SAMPLE_RATE = 16000  # Taxa de amostragem\n",
        "MAX_DURATION = 1  # Duração máxima em segundos\n",
        "\n",
        "# Função para carregar áudio com fallback\n",
        "def load_audio(file_path, sample_rate, max_duration, fallback_file=None):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Arquivo não encontrado: {file_path}\")\n",
        "        if fallback_file and os.path.exists(fallback_file):\n",
        "            print(f\"Usando arquivo substituto: {fallback_file}\")\n",
        "            file_path = fallback_file\n",
        "        else:\n",
        "            return None\n",
        "    try:\n",
        "        audio, sr = librosa.load(file_path, sr=sample_rate, mono=True, duration=max_duration)\n",
        "        return audio, sr\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar o arquivo {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Função para extrair características emocionais\n",
        "def extract_emotional_features(file_path):\n",
        "    fallback_files = glob.glob(\"mini_speech_commands/stop/*.wav\")  # Arquivos substitutos\n",
        "    fallback_file = fallback_files[0] if fallback_files else None\n",
        "    data = load_audio(file_path, SAMPLE_RATE, MAX_DURATION, fallback_file)\n",
        "    if data is None:\n",
        "        return None\n",
        "\n",
        "    audio, sr = data\n",
        "    try:\n",
        "        features = {\n",
        "            'pitch_mean': np.mean(librosa.yin(audio, fmin=100, fmax=800, sr=sr)),\n",
        "            'pitch_std': np.std(librosa.yin(audio, fmin=100, fmax=800, sr=sr)),\n",
        "            'rms_energy': np.mean(librosa.feature.rms(y=audio)[0]),\n",
        "            'zero_crossing_rate': np.mean(librosa.feature.zero_crossing_rate(audio)),\n",
        "            'spectral_centroid': np.mean(librosa.feature.spectral_centroid(y=audio, sr=sr)[0]),\n",
        "            'spectral_bandwidth': np.mean(librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]),\n",
        "            'spectral_rolloff': np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]),\n",
        "            'mfccs': librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "        }\n",
        "        return features\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao extrair características de {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Função para extrair espectrograma mel\n",
        "def extract_mel_spectrogram(file_path):\n",
        "    fallback_files = glob.glob(\"mini_speech_commands/stop/*.wav\")\n",
        "    fallback_file = fallback_files[0] if fallback_files else None\n",
        "    data = load_audio(file_path, SAMPLE_RATE, MAX_DURATION, fallback_file)\n",
        "    if data is None:\n",
        "        return None\n",
        "\n",
        "    audio, sr = data\n",
        "    try:\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)\n",
        "        mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "        return mel_spectrogram_db\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao extrair espectrograma de {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Função para criar o modelo de rede neural\n",
        "def create_emotional_command_model(input_shape):\n",
        "    input_spec = layers.Input(shape=input_shape, name='spectogram_input')\n",
        "    input_emotion = layers.Input(shape=(4,), name='emotional_features')\n",
        "\n",
        "    x = layers.Conv2D(32, 3, activation='relu')(input_spec)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    combined = layers.Concatenate()([x, input_emotion])\n",
        "    x = layers.Dense(128, activation='relu')(combined)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(len(COMMANDS), activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=[input_spec, input_emotion], outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Função principal de treinamento\n",
        "def train_emotional_command_recognition():\n",
        "    spectrograms, emotional_features, labels = [], [], []\n",
        "    fallback_files = glob.glob(\"mini_speech_commands/stop/*.wav\")\n",
        "    fallback_file = fallback_files[0] if fallback_files else None\n",
        "\n",
        "    for command in COMMANDS:\n",
        "        path = f\"mini_speech_commands/{command}\"\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"Diretório não encontrado: {path}\")\n",
        "            continue\n",
        "        for file in tqdm(glob.glob(os.path.join(path, \"*.wav\"))):\n",
        "            features = extract_emotional_features(file)\n",
        "            if features is None:\n",
        "                continue\n",
        "            spectrogram = extract_mel_spectrogram(file)\n",
        "            if spectrogram is None:\n",
        "                continue\n",
        "            spectrograms.append(spectrogram)\n",
        "            emotional_features.append([features['pitch_mean'], features['pitch_std'], features['rms_energy'], features['zero_crossing_rate']])\n",
        "            labels.append(COMMANDS.index(command))\n",
        "\n",
        "    if not spectrograms:\n",
        "        raise ValueError(\"Nenhum espectrograma foi extraído.\")\n",
        "\n",
        "    max_rows = max(spec.shape[0] for spec in spectrograms)\n",
        "    max_cols = max(spec.shape[1] for spec in spectrograms)\n",
        "\n",
        "    spectrograms = np.array([  # Pad spectrograms to the maximum size\n",
        "        np.pad(spec, ((0, max_rows - spec.shape[0]), (0, max_cols - spec.shape[1])), mode='constant')\n",
        "        for spec in spectrograms\n",
        "    ])[..., np.newaxis]\n",
        "    emotional_features = np.array(emotional_features)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    indices = np.random.permutation(len(spectrograms))\n",
        "    training_idx = indices[:int(0.8 * len(indices))]\n",
        "    test_idx = indices[int(0.8 * len(indices)):]\n",
        "\n",
        "    # Create and compile the model\n",
        "    model = create_emotional_command_model(spectrograms[0].shape)\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # EarlyStopping and ReduceLROnPlateau callback setup\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',  # Monitor the loss for early stopping\n",
        "            patience=5,  # Tuning patience to avoid stopping too early\n",
        "            restore_best_weights=True,  # Restore the best weights based on val_loss\n",
        "            mode='min'  # 'min' for monitoring loss, 'max' for accuracy\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',  # Reduce learning rate based on validation loss\n",
        "            factor=0.5,  # Reduce LR by a factor of 0.5\n",
        "            patience=3,  # Number of epochs to wait before reducing LR\n",
        "            mode='min'  # 'min' for loss\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        [spectrograms[training_idx], emotional_features[training_idx]],\n",
        "        labels[training_idx],\n",
        "        validation_data=(\n",
        "            [spectrograms[test_idx], emotional_features[test_idx]],\n",
        "            labels[test_idx]\n",
        "        ),\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Treina modelo\n",
        "    model = train_emotional_command_recognition()\n",
        "\n",
        "    # Exemplo de análise de um comando\n",
        "    test_file = \"mini_speech_commands/stop/0a7c2a8d_nohash_0.wav\"\n",
        "\n",
        "    # Check if the test file exists\n",
        "    if not os.path.exists(test_file):\n",
        "        print(f\"Arquivo não encontrado: {test_file}\")\n",
        "\n",
        "        # Choose a random file from the dataset\n",
        "        command = random.choice(COMMANDS)  # Select a random command\n",
        "        file_list = glob.glob(os.path.join(\"mini_speech_commands\", command, \"*.wav\"))  # Get list of files\n",
        "        test_file = random.choice(file_list)  # Choose a random file\n",
        "\n",
        "        print(f\"Usando arquivo aleatório: {test_file}\")\n",
        "\n",
        "    features = extract_emotional_features(test_file)\n",
        "    print(features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbqrTvslns2u",
        "outputId": "1a7a1198-3be9-4aa4-eb08-7e689d5fea8f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [01:15<00:00, 13.24it/s]\n",
            "100%|██████████| 1000/1000 [00:55<00:00, 18.17it/s]\n",
            "100%|██████████| 1000/1000 [00:55<00:00, 18.00it/s]\n",
            "100%|██████████| 1000/1000 [00:55<00:00, 18.16it/s]\n",
            "100%|██████████| 1000/1000 [00:55<00:00, 18.00it/s]\n",
            "100%|██████████| 1000/1000 [00:55<00:00, 17.90it/s]\n",
            "100%|██████████| 1000/1000 [00:54<00:00, 18.22it/s]\n",
            "100%|██████████| 1000/1000 [00:55<00:00, 18.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 253ms/step - accuracy: 0.2186 - loss: 3.1887 - val_accuracy: 0.3806 - val_loss: 1.6284 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 229ms/step - accuracy: 0.3225 - loss: 1.6628 - val_accuracy: 0.3831 - val_loss: 1.6772 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 235ms/step - accuracy: 0.3633 - loss: 1.5257 - val_accuracy: 0.4494 - val_loss: 1.4442 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 227ms/step - accuracy: 0.4074 - loss: 1.4171 - val_accuracy: 0.5144 - val_loss: 1.2688 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 227ms/step - accuracy: 0.4521 - loss: 1.2978 - val_accuracy: 0.5481 - val_loss: 1.1434 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 233ms/step - accuracy: 0.4874 - loss: 1.2082 - val_accuracy: 0.3338 - val_loss: 1.9563 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 227ms/step - accuracy: 0.5097 - loss: 1.1419 - val_accuracy: 0.6338 - val_loss: 0.9927 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 227ms/step - accuracy: 0.5387 - loss: 1.0871 - val_accuracy: 0.5894 - val_loss: 1.0430 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 234ms/step - accuracy: 0.5522 - loss: 1.0388 - val_accuracy: 0.6587 - val_loss: 0.9322 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 226ms/step - accuracy: 0.5831 - loss: 0.9828 - val_accuracy: 0.7237 - val_loss: 0.7609 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 226ms/step - accuracy: 0.6048 - loss: 0.9082 - val_accuracy: 0.6425 - val_loss: 1.1185 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 241ms/step - accuracy: 0.6131 - loss: 0.8781 - val_accuracy: 0.5325 - val_loss: 1.5063 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 223ms/step - accuracy: 0.6429 - loss: 0.8461 - val_accuracy: 0.6331 - val_loss: 1.0170 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 225ms/step - accuracy: 0.6680 - loss: 0.7470 - val_accuracy: 0.8256 - val_loss: 0.4819 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 227ms/step - accuracy: 0.6856 - loss: 0.7010 - val_accuracy: 0.8338 - val_loss: 0.4588 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 221ms/step - accuracy: 0.7188 - loss: 0.6390 - val_accuracy: 0.8244 - val_loss: 0.5304 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 220ms/step - accuracy: 0.7545 - loss: 0.5787 - val_accuracy: 0.8462 - val_loss: 0.4242 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 230ms/step - accuracy: 0.7572 - loss: 0.5563 - val_accuracy: 0.8525 - val_loss: 0.4294 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 224ms/step - accuracy: 0.7494 - loss: 0.5744 - val_accuracy: 0.8125 - val_loss: 0.5251 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 223ms/step - accuracy: 0.7678 - loss: 0.5352 - val_accuracy: 0.8344 - val_loss: 0.4992 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 232ms/step - accuracy: 0.8008 - loss: 0.4689 - val_accuracy: 0.8375 - val_loss: 0.5270 - learning_rate: 2.5000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 230ms/step - accuracy: 0.8024 - loss: 0.4523 - val_accuracy: 0.8744 - val_loss: 0.3724 - learning_rate: 2.5000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 224ms/step - accuracy: 0.8117 - loss: 0.4322 - val_accuracy: 0.8744 - val_loss: 0.3793 - learning_rate: 2.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 240ms/step - accuracy: 0.8227 - loss: 0.4052 - val_accuracy: 0.8669 - val_loss: 0.3864 - learning_rate: 2.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 223ms/step - accuracy: 0.8145 - loss: 0.4146 - val_accuracy: 0.8569 - val_loss: 0.4458 - learning_rate: 2.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 224ms/step - accuracy: 0.8448 - loss: 0.3664 - val_accuracy: 0.8869 - val_loss: 0.3548 - learning_rate: 1.2500e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 232ms/step - accuracy: 0.8400 - loss: 0.3630 - val_accuracy: 0.8769 - val_loss: 0.3663 - learning_rate: 1.2500e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 223ms/step - accuracy: 0.8580 - loss: 0.3447 - val_accuracy: 0.8569 - val_loss: 0.4352 - learning_rate: 1.2500e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 226ms/step - accuracy: 0.8507 - loss: 0.3406 - val_accuracy: 0.8756 - val_loss: 0.3771 - learning_rate: 1.2500e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 232ms/step - accuracy: 0.8550 - loss: 0.3326 - val_accuracy: 0.8763 - val_loss: 0.3734 - learning_rate: 6.2500e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 225ms/step - accuracy: 0.8733 - loss: 0.2999 - val_accuracy: 0.8856 - val_loss: 0.3510 - learning_rate: 6.2500e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 222ms/step - accuracy: 0.8641 - loss: 0.3176 - val_accuracy: 0.8794 - val_loss: 0.3642 - learning_rate: 6.2500e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 221ms/step - accuracy: 0.8658 - loss: 0.3140 - val_accuracy: 0.8831 - val_loss: 0.3610 - learning_rate: 6.2500e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 221ms/step - accuracy: 0.8658 - loss: 0.3170 - val_accuracy: 0.8806 - val_loss: 0.3632 - learning_rate: 6.2500e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 220ms/step - accuracy: 0.8671 - loss: 0.3061 - val_accuracy: 0.8800 - val_loss: 0.3619 - learning_rate: 3.1250e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 225ms/step - accuracy: 0.8777 - loss: 0.2915 - val_accuracy: 0.8819 - val_loss: 0.3710 - learning_rate: 3.1250e-05\n",
            "Arquivo não encontrado: mini_speech_commands/stop/0a7c2a8d_nohash_0.wav\n",
            "Usando arquivo aleatório: mini_speech_commands/go/c7aa72e6_nohash_0.wav\n",
            "{'pitch_mean': 196.674820190947, 'pitch_std': 110.03536454243074, 'rms_energy': 0.024160821, 'zero_crossing_rate': 0.2427825927734375, 'spectral_centroid': 2522.720569996505, 'spectral_bandwidth': 1861.3793062189175, 'spectral_rolloff': 4759.033203125, 'mfccs': array([[-4.63801605e+02, -4.35332642e+02, -4.32640747e+02,\n",
            "        -4.32342072e+02, -4.33789703e+02, -4.36608429e+02,\n",
            "        -4.37285583e+02, -4.36662903e+02, -4.41760559e+02,\n",
            "        -4.38349731e+02, -4.11746399e+02, -3.85646210e+02,\n",
            "        -3.34988892e+02, -2.46738220e+02, -1.89290894e+02,\n",
            "        -1.50684845e+02, -1.44493332e+02, -1.45455994e+02,\n",
            "        -1.47825653e+02, -1.67508652e+02, -1.95585388e+02,\n",
            "        -2.38681488e+02, -2.96346497e+02, -3.42612061e+02,\n",
            "        -3.71412262e+02, -3.92943909e+02, -4.05847534e+02,\n",
            "        -4.18564423e+02, -4.26197083e+02, -4.31865295e+02,\n",
            "        -4.29142761e+02, -4.45436951e+02],\n",
            "       [ 3.29863663e+01,  3.59464035e+01,  3.99460068e+01,\n",
            "         4.19039192e+01,  4.29025497e+01,  4.26195869e+01,\n",
            "         4.48516693e+01,  4.84401512e+01,  4.96795044e+01,\n",
            "         4.35346985e+01,  4.68071365e+01,  6.72073517e+01,\n",
            "         4.49078598e+01,  1.99224892e+01,  3.12648563e+01,\n",
            "         4.56540527e+01,  4.69081306e+01,  5.34574890e+01,\n",
            "         6.72356873e+01,  7.93463516e+01,  9.80258179e+01,\n",
            "         1.11661804e+02,  1.09844398e+02,  8.01983337e+01,\n",
            "         5.71146927e+01,  5.03207474e+01,  5.01064835e+01,\n",
            "         4.87523232e+01,  4.61684875e+01,  4.07700882e+01,\n",
            "         4.37459755e+01,  4.28284836e+01],\n",
            "       [-4.96596527e+00, -1.35172491e+01, -1.71503983e+01,\n",
            "        -1.13030281e+01, -1.13078232e+01, -1.09506903e+01,\n",
            "        -1.27158298e+01, -1.32614517e+01, -1.18030272e+01,\n",
            "        -1.77954540e+01,  2.85406733e+00,  2.94924049e+01,\n",
            "         2.82349777e+01,  3.63206558e+01,  2.27057991e+01,\n",
            "        -1.63847828e+01, -4.08829842e+01, -5.34385223e+01,\n",
            "        -5.96126328e+01, -5.41036682e+01, -4.59428864e+01,\n",
            "        -2.53010979e+01, -1.51838613e+00, -2.21147275e+00,\n",
            "        -1.13411865e+01, -1.68416958e+01, -1.77816849e+01,\n",
            "        -1.50511990e+01, -9.06920052e+00, -6.92911625e+00,\n",
            "        -1.13374147e+01, -1.72314072e+01],\n",
            "       [ 2.36603546e+01,  2.16526814e+01,  1.97656384e+01,\n",
            "         2.11492653e+01,  2.13717270e+01,  2.57671642e+01,\n",
            "         2.76356430e+01,  2.56120396e+01,  2.19722748e+01,\n",
            "         1.99592381e+01,  3.48785019e+01,  4.91273689e+01,\n",
            "         8.45772400e+01,  9.59118118e+01,  8.48127975e+01,\n",
            "         6.80492935e+01,  6.20907135e+01,  5.42667847e+01,\n",
            "         3.94259109e+01,  2.84365063e+01,  1.68430882e+01,\n",
            "         6.29330063e+00,  1.18978767e+01,  2.41484871e+01,\n",
            "         2.09176407e+01,  1.70510445e+01,  1.36996622e+01,\n",
            "         1.63967209e+01,  2.14292450e+01,  2.66784210e+01,\n",
            "         2.31138191e+01,  1.92827625e+01],\n",
            "       [-2.04773235e+01, -1.38148098e+01, -1.20825825e+01,\n",
            "        -1.42170906e+01, -9.37758827e+00, -5.03782463e+00,\n",
            "         8.31442177e-01, -2.26019740e+00, -7.89157724e+00,\n",
            "        -9.66215324e+00, -1.66617413e+01, -1.80650463e+01,\n",
            "        -3.60804863e+01, -8.53005447e+01, -1.03661713e+02,\n",
            "        -1.06903168e+02, -9.97386627e+01, -8.13639526e+01,\n",
            "        -7.17700806e+01, -7.04311371e+01, -6.84480896e+01,\n",
            "        -5.87196732e+01, -4.48450356e+01, -3.15802250e+01,\n",
            "        -2.63938026e+01, -2.28380241e+01, -1.88939896e+01,\n",
            "        -1.18964100e+01, -1.49738140e+01, -1.06552563e+01,\n",
            "        -5.78877306e+00, -8.82498264e+00],\n",
            "       [ 2.74347363e+01,  3.03890362e+01,  2.60377464e+01,\n",
            "         2.28303871e+01,  2.12869644e+01,  1.85522232e+01,\n",
            "         2.13940811e+01,  2.19917946e+01,  2.36362762e+01,\n",
            "         2.16210823e+01,  3.51938934e+01,  4.02873840e+01,\n",
            "         3.54977798e+01,  5.78525352e+00, -1.52673426e+01,\n",
            "        -1.92924042e+01, -1.26967421e+01, -7.07276165e-01,\n",
            "         1.13412323e+01,  2.26549492e+01,  2.76460686e+01,\n",
            "         2.79075317e+01,  2.11347198e+01,  2.30889206e+01,\n",
            "         2.52394238e+01,  2.61441078e+01,  2.41040421e+01,\n",
            "         2.74332924e+01,  2.95606003e+01,  2.62504406e+01,\n",
            "         2.75838852e+01,  2.64628754e+01],\n",
            "       [-1.37330475e+01, -1.45962086e+01, -9.32644176e+00,\n",
            "        -7.31456041e+00, -6.55056953e+00, -4.60800505e+00,\n",
            "        -4.33393764e+00, -9.00144005e+00, -1.06588488e+01,\n",
            "        -1.35199518e+01, -2.76423607e+01, -3.41531372e+01,\n",
            "        -2.23524818e+01, -4.91958656e+01, -5.83617554e+01,\n",
            "        -5.62793884e+01, -5.08551750e+01, -5.69661522e+01,\n",
            "        -6.35686569e+01, -6.57414169e+01, -6.18002090e+01,\n",
            "        -5.10180664e+01, -4.24686928e+01, -3.60520401e+01,\n",
            "        -2.13636627e+01, -1.79599648e+01, -1.94426765e+01,\n",
            "        -1.64696541e+01, -1.26852360e+01, -1.03832340e+01,\n",
            "        -1.31485214e+01, -9.63567352e+00],\n",
            "       [ 1.36165371e+01,  1.49794121e+01,  1.40926247e+01,\n",
            "         1.51154442e+01,  1.49557476e+01,  1.53762970e+01,\n",
            "         1.71313438e+01,  1.06940708e+01,  8.47035027e+00,\n",
            "         1.69963417e+01,  1.53626823e+01,  9.17473316e-01,\n",
            "        -1.11644745e+01, -6.78327703e+00,  1.13176670e+01,\n",
            "         3.38038635e+01,  4.13939362e+01,  3.47415428e+01,\n",
            "         2.09572220e+01,  1.88820958e+00, -1.69709530e+01,\n",
            "        -1.97704525e+01, -6.11820316e+00,  3.20640969e+00,\n",
            "         1.52446108e+01,  1.39467936e+01,  8.76083279e+00,\n",
            "         1.36020088e+01,  1.74826164e+01,  1.99276047e+01,\n",
            "         1.76606216e+01,  7.86288738e+00],\n",
            "       [-8.11688900e+00, -3.04882240e+00, -4.49628544e+00,\n",
            "        -5.38950968e+00, -4.97039080e+00, -6.09349060e+00,\n",
            "        -3.57222748e+00, -3.56309891e+00, -2.95648217e+00,\n",
            "         1.77148223e-01, -1.00714512e+01, -2.82414780e+01,\n",
            "        -4.34210129e+01, -4.25111694e+01, -4.17521362e+01,\n",
            "        -3.56845245e+01, -2.52233391e+01, -9.19625854e+00,\n",
            "        -8.22807670e-01,  8.21201706e+00, -3.72665501e+00,\n",
            "        -2.00825996e+01, -2.53832321e+01, -2.25101471e+01,\n",
            "        -1.41094780e+01, -5.71477699e+00, -6.20177555e+00,\n",
            "        -4.51623631e+00,  2.57445812e-01,  4.60373640e+00,\n",
            "         2.77332306e+00, -4.17076731e+00],\n",
            "       [ 1.72982275e+00,  7.28482628e+00,  8.34337139e+00,\n",
            "         8.63226891e+00,  1.08124008e+01,  1.52295380e+01,\n",
            "         1.73091717e+01,  1.34834957e+01,  1.15585928e+01,\n",
            "         1.17345190e+01, -9.59480572e+00, -2.64718018e+01,\n",
            "        -1.79701591e+00,  2.20288506e+01,  1.55642204e+01,\n",
            "         2.78312349e+00, -3.41959447e-01, -3.80857915e-01,\n",
            "        -2.89904571e+00,  3.59565306e+00,  3.04762483e+00,\n",
            "         3.78218502e-01, -7.92724609e+00, -1.24434462e+01,\n",
            "        -6.54794645e+00,  1.45918941e+00,  6.38014412e+00,\n",
            "         1.02704334e+01,  8.06353283e+00,  1.04308186e+01,\n",
            "         1.01191130e+01,  6.72865772e+00],\n",
            "       [-1.20308018e+00, -1.49997735e+00, -5.51670742e+00,\n",
            "        -8.02916050e+00, -1.18288078e+01, -1.05350904e+01,\n",
            "        -1.09766073e+01, -6.61160278e+00, -3.96136713e+00,\n",
            "        -2.31945658e+00, -6.40552473e+00, -2.35211525e+01,\n",
            "        -4.46879044e+01, -2.87608929e+01, -2.13811264e+01,\n",
            "        -1.51409740e+01, -1.06033611e+01, -1.68426819e+01,\n",
            "        -2.39581757e+01, -2.27593803e+01, -1.21140842e+01,\n",
            "        -7.95899630e+00, -1.07700605e+01, -8.19071960e+00,\n",
            "        -6.75355721e+00, -9.46564102e+00, -1.32263355e+01,\n",
            "        -9.16171646e+00, -6.63395596e+00, -3.99976993e+00,\n",
            "        -4.46090126e+00, -1.90457773e+00],\n",
            "       [ 5.85772896e+00,  6.32095385e+00,  4.78360367e+00,\n",
            "         7.45209217e+00,  9.26664543e+00,  5.90724850e+00,\n",
            "         3.63704395e+00,  6.49067974e+00,  9.94373512e+00,\n",
            "         6.51178169e+00, -1.30613785e+01, -2.46443672e+01,\n",
            "        -2.46939240e+01, -7.74283886e+00, -1.60847282e+01,\n",
            "        -1.71859283e+01, -1.23859482e+01, -5.45510244e+00,\n",
            "        -6.33873844e+00, -9.99939728e+00, -1.34603453e+01,\n",
            "        -1.45932159e+01, -1.18219318e+01, -5.67974949e+00,\n",
            "         5.01633286e-02, -2.82597828e+00, -6.67670536e+00,\n",
            "        -5.88956308e+00, -1.68529463e+00,  7.57916784e+00,\n",
            "         1.31026974e+01,  1.63763638e+01],\n",
            "       [-1.56056643e+00, -3.57631397e+00,  5.65615177e-01,\n",
            "        -4.67311502e-01, -5.04646683e+00, -9.39511585e+00,\n",
            "        -7.52572823e+00, -5.88758850e+00, -4.64705324e+00,\n",
            "        -1.84468579e+00, -1.34472752e+01, -2.01745987e+01,\n",
            "        -8.72405720e+00, -7.48634458e-01, -5.38302326e+00,\n",
            "        -9.24908447e+00, -1.60232010e+01, -1.76094971e+01,\n",
            "        -1.51147718e+01, -1.05496941e+01, -8.32820988e+00,\n",
            "        -1.10506878e+01, -1.05834103e+01, -6.33395147e+00,\n",
            "        -1.97665894e+00,  6.11519754e-01, -3.11768174e+00,\n",
            "        -6.97815514e+00, -6.39205122e+00, -3.23446608e+00,\n",
            "         7.71208227e-01,  4.47484970e+00]], dtype=float32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Configurações iniciais\n",
        "COMMANDS = ['down', 'go', 'left', 'no', 'right', 'stop', 'up', 'yes']\n",
        "SAMPLE_RATE = 16000  # Taxa de amostragem\n",
        "MAX_DURATION = 1  # Duração máxima em segundos\n",
        "\n",
        "# Função para carregar áudio com fallback\n",
        "def load_audio(file_path, sample_rate, max_duration, fallback_file=None):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Arquivo não encontrado: {file_path}\")\n",
        "        if fallback_file and os.path.exists(fallback_file):\n",
        "            print(f\"Usando arquivo substituto: {fallback_file}\")\n",
        "            file_path = fallback_file\n",
        "        else:\n",
        "            return None\n",
        "    try:\n",
        "        audio, sr = librosa.load(file_path, sr=sample_rate, mono=True, duration=max_duration)\n",
        "        return audio, sr\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar o arquivo {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Função para extrair características emocionais\n",
        "def extract_emotional_features(file_path):\n",
        "    fallback_files = glob.glob(\"mini_speech_commands/stop/*.wav\")  # Arquivos substitutos\n",
        "    fallback_file = fallback_files[0] if fallback_files else None\n",
        "    data = load_audio(file_path, SAMPLE_RATE, MAX_DURATION, fallback_file)\n",
        "    if data is None:\n",
        "        return None\n",
        "\n",
        "    audio, sr = data\n",
        "    try:\n",
        "        features = {\n",
        "            'pitch_mean': np.mean(librosa.yin(audio, fmin=100, fmax=800, sr=sr)),\n",
        "            'pitch_std': np.std(librosa.yin(audio, fmin=100, fmax=800, sr=sr)),\n",
        "            'rms_energy': np.mean(librosa.feature.rms(y=audio)[0]),\n",
        "            'zero_crossing_rate': np.mean(librosa.feature.zero_crossing_rate(audio)),\n",
        "            'spectral_centroid': np.mean(librosa.feature.spectral_centroid(y=audio, sr=sr)[0]),\n",
        "            'spectral_bandwidth': np.mean(librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]),\n",
        "            'spectral_rolloff': np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]),\n",
        "            'mfccs': librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "        }\n",
        "        return features\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao extrair características de {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Função para extrair espectrograma mel\n",
        "def extract_mel_spectrogram(file_path):\n",
        "    fallback_files = glob.glob(\"mini_speech_commands/stop/*.wav\")\n",
        "    fallback_file = fallback_files[0] if fallback_files else None\n",
        "    data = load_audio(file_path, SAMPLE_RATE, MAX_DURATION, fallback_file)\n",
        "    if data is None:\n",
        "        return None\n",
        "\n",
        "    audio, sr = data\n",
        "    try:\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)\n",
        "        mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "        return mel_spectrogram_db\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao extrair espectrograma de {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Função principal de treinamento\n",
        "def train_emotional_command_recognition():\n",
        "    spectrograms, emotional_features, labels = [], [], []\n",
        "    fallback_files = glob.glob(\"mini_speech_commands/stop/*.wav\")\n",
        "    fallback_file = fallback_files[0] if fallback_files else None\n",
        "\n",
        "    for command in COMMANDS:\n",
        "        path = f\"mini_speech_commands/{command}\"\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"Diretório não encontrado: {path}\")\n",
        "            continue\n",
        "        for file in tqdm(glob.glob(os.path.join(path, \"*.wav\"))):\n",
        "            features = extract_emotional_features(file)\n",
        "            if features is None:\n",
        "                continue\n",
        "            spectrogram = extract_mel_spectrogram(file)\n",
        "            if spectrogram is None:\n",
        "                continue\n",
        "            spectrograms.append(spectrogram)\n",
        "            emotional_features.append([features['pitch_mean'], features['pitch_std'], features['rms_energy'], features['zero_crossing_rate']])\n",
        "            labels.append(COMMANDS.index(command))\n",
        "\n",
        "    if not spectrograms:\n",
        "        raise ValueError(\"Nenhum espectrograma foi extraído.\")\n",
        "\n",
        "    max_rows = max(spec.shape[0] for spec in spectrograms)\n",
        "    max_cols = max(spec.shape[1] for spec in spectrograms)\n",
        "\n",
        "    spectrograms = np.array([\n",
        "        np.pad(spec, ((0, max_rows - spec.shape[0]), (0, max_cols - spec.shape[1])), mode='constant')\n",
        "        for spec in spectrograms\n",
        "    ])[..., np.newaxis]\n",
        "    emotional_features = np.array(emotional_features)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    indices = np.random.permutation(len(spectrograms))\n",
        "    training_idx = indices[:int(0.8 * len(indices))]\n",
        "    test_idx = indices[int(0.8 * len(indices)):]\n",
        "\n",
        "    model = create_emotional_command_model(spectrograms[0].shape)\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        [spectrograms[training_idx], emotional_features[training_idx]],\n",
        "        labels[training_idx],\n",
        "        validation_data=( [spectrograms[test_idx], emotional_features[test_idx]], labels[test_idx]),\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        callbacks=[\n",
        "            tf.keras.callbacks.EarlyStopping(patience=5),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2)\n",
        "        ]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Execução\n",
        "if __name__ == \"__main__\":\n",
        "    model = train_emotional_command_recognition()\n",
        "    test_file = \"mini_speech_commands/stop/0a7c2a8d_nohash_0.wav\"\n",
        "    features = extract_emotional_features(test_file)\n",
        "    print(features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIOPS_M6aZXs",
        "outputId": "547efafc-3ee4-414a-904a-03eaace06911"
      },
      "execution_count": 24,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:52<00:00, 19.18it/s]\n",
            "100%|██████████| 1000/1000 [00:53<00:00, 18.65it/s]\n",
            "100%|██████████| 1000/1000 [00:53<00:00, 18.74it/s]\n",
            "100%|██████████| 1000/1000 [00:53<00:00, 18.82it/s]\n",
            "100%|██████████| 1000/1000 [00:51<00:00, 19.44it/s]\n",
            "100%|██████████| 1000/1000 [00:53<00:00, 18.83it/s]\n",
            "100%|██████████| 1000/1000 [00:52<00:00, 18.93it/s]\n",
            "100%|██████████| 1000/1000 [00:51<00:00, 19.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 232ms/step - accuracy: 0.2291 - loss: 3.3219 - val_accuracy: 0.3919 - val_loss: 1.6209 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 226ms/step - accuracy: 0.3597 - loss: 1.6277 - val_accuracy: 0.5375 - val_loss: 1.2810 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 248ms/step - accuracy: 0.4268 - loss: 1.4465 - val_accuracy: 0.5869 - val_loss: 1.2056 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 235ms/step - accuracy: 0.4672 - loss: 1.3224 - val_accuracy: 0.5019 - val_loss: 1.4374 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 226ms/step - accuracy: 0.4944 - loss: 1.2313 - val_accuracy: 0.6162 - val_loss: 1.0339 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 225ms/step - accuracy: 0.5167 - loss: 1.1621 - val_accuracy: 0.6925 - val_loss: 0.8651 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 238ms/step - accuracy: 0.5557 - loss: 1.0883 - val_accuracy: 0.5725 - val_loss: 1.1696 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 226ms/step - accuracy: 0.5772 - loss: 1.0025 - val_accuracy: 0.6037 - val_loss: 1.1641 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 229ms/step - accuracy: 0.6083 - loss: 0.9400 - val_accuracy: 0.7894 - val_loss: 0.6513 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 243ms/step - accuracy: 0.6372 - loss: 0.8296 - val_accuracy: 0.7850 - val_loss: 0.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 233ms/step - accuracy: 0.6716 - loss: 0.7742 - val_accuracy: 0.7825 - val_loss: 0.6954 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 226ms/step - accuracy: 0.6792 - loss: 0.7560 - val_accuracy: 0.7250 - val_loss: 0.7122 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 228ms/step - accuracy: 0.7048 - loss: 0.6762 - val_accuracy: 0.8281 - val_loss: 0.5526 - learning_rate: 2.5000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 236ms/step - accuracy: 0.7275 - loss: 0.6430 - val_accuracy: 0.8325 - val_loss: 0.5121 - learning_rate: 2.5000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 229ms/step - accuracy: 0.7334 - loss: 0.6134 - val_accuracy: 0.8512 - val_loss: 0.4454 - learning_rate: 2.5000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 227ms/step - accuracy: 0.7610 - loss: 0.5680 - val_accuracy: 0.8375 - val_loss: 0.4887 - learning_rate: 2.5000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 237ms/step - accuracy: 0.7589 - loss: 0.5590 - val_accuracy: 0.8512 - val_loss: 0.4853 - learning_rate: 2.5000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 228ms/step - accuracy: 0.8034 - loss: 0.4761 - val_accuracy: 0.8656 - val_loss: 0.4083 - learning_rate: 1.2500e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 228ms/step - accuracy: 0.7994 - loss: 0.4841 - val_accuracy: 0.8662 - val_loss: 0.4077 - learning_rate: 1.2500e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 230ms/step - accuracy: 0.8089 - loss: 0.4452 - val_accuracy: 0.8750 - val_loss: 0.4152 - learning_rate: 1.2500e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 230ms/step - accuracy: 0.8311 - loss: 0.4362 - val_accuracy: 0.8763 - val_loss: 0.4011 - learning_rate: 1.2500e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 228ms/step - accuracy: 0.8322 - loss: 0.4200 - val_accuracy: 0.8700 - val_loss: 0.4049 - learning_rate: 1.2500e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 233ms/step - accuracy: 0.8280 - loss: 0.4110 - val_accuracy: 0.8631 - val_loss: 0.4286 - learning_rate: 1.2500e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 239ms/step - accuracy: 0.8396 - loss: 0.3986 - val_accuracy: 0.8763 - val_loss: 0.4204 - learning_rate: 6.2500e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 227ms/step - accuracy: 0.8455 - loss: 0.3707 - val_accuracy: 0.8744 - val_loss: 0.4063 - learning_rate: 6.2500e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 232ms/step - accuracy: 0.8500 - loss: 0.3671 - val_accuracy: 0.8737 - val_loss: 0.4212 - learning_rate: 3.1250e-05\n",
            "Arquivo não encontrado: mini_speech_commands/stop/0a7c2a8d_nohash_0.wav\n",
            "Usando arquivo substituto: mini_speech_commands/stop/24befdb3_nohash_3.wav\n",
            "{'pitch_mean': 235.66168273018644, 'pitch_std': 166.42209991030094, 'rms_energy': 0.036354795, 'zero_crossing_rate': 0.1298675537109375, 'spectral_centroid': 1774.6510397412358, 'spectral_bandwidth': 1662.8038044055616, 'spectral_rolloff': 3365.234375, 'mfccs': array([[-5.08440826e+02, -4.82587036e+02, -4.74714355e+02,\n",
            "        -4.69221008e+02, -4.77429077e+02, -4.73426636e+02,\n",
            "        -3.97125977e+02, -3.15152740e+02, -2.75789062e+02,\n",
            "        -2.74758728e+02, -2.85448578e+02, -1.81706024e+02,\n",
            "        -1.03101357e+02, -1.03704796e+02, -1.22145996e+02,\n",
            "        -1.36795990e+02, -1.78504883e+02, -2.63049591e+02,\n",
            "        -3.59010651e+02, -4.03241547e+02, -4.36485657e+02,\n",
            "        -4.59550446e+02, -4.56122375e+02, -4.59503265e+02,\n",
            "        -4.77582184e+02, -4.79509796e+02, -4.77218079e+02,\n",
            "        -4.60084045e+02, -4.28123718e+02, -4.30112579e+02,\n",
            "        -4.51111328e+02, -4.87595856e+02],\n",
            "       [ 9.76012802e+01,  1.06488983e+02,  1.03932358e+02,\n",
            "         9.72235718e+01,  9.45832825e+01,  8.90373993e+01,\n",
            "         3.03374233e+01, -1.92833023e+01, -3.82951546e+01,\n",
            "        -3.85714417e+01, -2.37524567e+01,  8.28942719e+01,\n",
            "         1.36825043e+02,  1.86813049e+02,  2.07377136e+02,\n",
            "         1.99708542e+02,  1.99974686e+02,  2.03345673e+02,\n",
            "         1.46175934e+02,  9.77062683e+01,  9.20919647e+01,\n",
            "         9.43227005e+01,  9.53114471e+01,  1.03258102e+02,\n",
            "         1.12162384e+02,  1.17810181e+02,  1.19106689e+02,\n",
            "         1.13167664e+02,  1.11742134e+02,  1.13049606e+02,\n",
            "         1.04279922e+02,  9.77525482e+01],\n",
            "       [ 1.86202946e+01,  1.41154919e+01,  1.44035463e+01,\n",
            "         1.24839420e+01,  1.43867702e+01,  8.13080406e+00,\n",
            "         1.89692955e+01,  4.45105667e+01,  6.32584381e+01,\n",
            "         7.26195221e+01,  5.13046722e+01, -2.64769363e+00,\n",
            "        -2.76838837e+01, -3.92529297e+01, -2.97881126e+01,\n",
            "        -2.68393631e+01, -2.06353073e+01,  2.51923847e+00,\n",
            "         2.48233738e+01,  1.45722370e+01,  1.62723217e+01,\n",
            "         2.37699699e+01,  2.87455330e+01,  2.55136585e+01,\n",
            "         1.89856606e+01,  1.57574196e+01,  2.08456364e+01,\n",
            "         1.37135143e+01, -1.86107302e+00,  7.64948845e+00,\n",
            "         1.83846130e+01,  2.15953751e+01],\n",
            "       [ 5.25615072e+00,  1.12444687e+01,  1.31580658e+01,\n",
            "         1.05630178e+01,  1.48156452e+01,  2.23224792e+01,\n",
            "         2.89310150e+01,  2.98438568e+01,  3.18605003e+01,\n",
            "         3.47326813e+01,  3.77775345e+01,  3.43184624e+01,\n",
            "         9.77078342e+00, -1.01341772e+01, -1.84214859e+01,\n",
            "        -1.90564728e+01, -1.02001286e+01, -1.53112054e+00,\n",
            "         5.98907089e+00,  7.79912615e+00,  1.63280029e+01,\n",
            "         1.81036148e+01,  8.88012409e+00,  9.08957386e+00,\n",
            "         9.36508942e+00,  5.61268473e+00,  4.89822865e+00,\n",
            "         5.05276859e-01, -4.15439278e-01,  2.91141272e+00,\n",
            "         8.31333542e+00,  1.35745049e+01],\n",
            "       [ 3.98275805e+00,  4.50860071e+00,  4.58174515e+00,\n",
            "        -1.34821570e+00,  5.26407242e+00,  8.73345757e+00,\n",
            "        -2.15865974e+01, -2.75895195e+01, -3.32292633e+01,\n",
            "        -3.06511536e+01, -2.75855751e+01, -2.45555401e+01,\n",
            "        -2.14609070e+01, -2.33608322e+01, -3.82573090e+01,\n",
            "        -4.88114853e+01, -4.41243362e+01, -3.44403687e+01,\n",
            "        -8.47648716e+00, -2.45762444e+00,  5.65895557e-01,\n",
            "         5.60995293e+00,  1.14386454e+01,  1.74139652e+01,\n",
            "         1.34411221e+01,  5.82871151e+00,  3.16580081e+00,\n",
            "        -1.05522096e+00, -9.73157692e+00, -8.31509209e+00,\n",
            "         6.66471577e+00,  1.94311676e+01],\n",
            "       [ 1.02254117e+00, -1.01303616e+01, -1.49431362e+01,\n",
            "        -1.67019348e+01, -1.78246689e+01, -1.32969265e+01,\n",
            "         2.63227615e+01,  3.75630875e+01,  3.52315865e+01,\n",
            "         3.47115555e+01,  2.22303200e+01, -5.02546310e+00,\n",
            "        -4.99024916e+00, -1.16216125e+01, -1.98309879e+01,\n",
            "        -1.96644478e+01, -1.68826256e+01, -1.36329422e+01,\n",
            "        -8.05377960e+00, -1.82254505e+01, -2.60956593e+01,\n",
            "        -2.96870899e+01, -2.75795422e+01, -1.98205948e+01,\n",
            "        -1.87862206e+01, -2.47755318e+01, -2.48401680e+01,\n",
            "        -2.45849171e+01, -1.40075016e+01, -6.18015575e+00,\n",
            "        -3.32592583e+00, -4.54870605e+00],\n",
            "       [ 1.98549724e+00, -6.46327209e+00, -1.07588615e+01,\n",
            "        -1.36472082e+01, -1.39255257e+01, -2.38430882e+01,\n",
            "        -4.41049805e+01, -3.45445442e+01, -2.77483330e+01,\n",
            "        -1.68764992e+01, -7.52388191e+00, -7.58686352e+00,\n",
            "        -8.78052330e+00, -8.68460846e+00,  2.48548698e+00,\n",
            "         2.63822460e+00, -3.61191273e+00, -5.97915125e+00,\n",
            "        -3.03126526e+00, -1.13282290e+01, -1.38092756e+01,\n",
            "        -1.29658003e+01, -1.38922806e+01, -2.04908466e+01,\n",
            "        -2.91438560e+01, -2.97210350e+01, -2.43669968e+01,\n",
            "        -1.40011683e+01, -1.98095775e+00, -2.53524065e+00,\n",
            "        -6.79037857e+00, -8.45409584e+00],\n",
            "       [-4.38512039e+00, -7.07082415e+00, -9.61602974e+00,\n",
            "        -6.31938076e+00, -7.14527702e+00, -1.62889538e+01,\n",
            "        -2.33159485e+01, -2.95421906e+01, -2.62554626e+01,\n",
            "        -2.11667500e+01, -2.50849190e+01, -3.94101868e+01,\n",
            "        -3.55228729e+01, -1.90413628e+01, -5.31462002e+00,\n",
            "         4.87613821e+00,  1.42153764e+00, -6.08984852e+00,\n",
            "        -4.48165274e+00, -5.86019611e+00, -4.51471949e+00,\n",
            "        -4.25538635e+00, -8.27218914e+00, -1.05897369e+01,\n",
            "        -9.69165611e+00, -9.94157982e+00, -7.37132740e+00,\n",
            "        -6.94529200e+00,  1.80574465e+00,  5.08003473e+00,\n",
            "         1.57919431e+00,  6.65613890e-01],\n",
            "       [-5.81784868e+00, -6.01356983e+00, -3.86385727e+00,\n",
            "        -2.08623695e+00, -1.16623437e+00,  1.26300516e+01,\n",
            "         1.84083481e+01,  6.37442827e-01,  8.60008538e-01,\n",
            "         2.88457513e-01, -1.08412790e+01, -1.52111168e+01,\n",
            "        -1.87655945e+01, -2.87257023e+01, -2.89451084e+01,\n",
            "        -2.75328693e+01, -2.65708694e+01, -1.43550081e+01,\n",
            "        -1.41649876e+01, -1.96117706e+01, -1.72514534e+01,\n",
            "        -9.93482780e+00, -1.04980907e+01, -1.12160206e+01,\n",
            "        -1.91815019e+00,  8.17984772e+00,  7.04754591e+00,\n",
            "         9.89488959e-01,  1.51097059e+00, -7.53189921e-01,\n",
            "         1.06888115e-02,  4.41204357e+00],\n",
            "       [-8.88874817e+00, -1.40956192e+01, -1.53272319e+00,\n",
            "         7.47305822e+00,  8.17159653e+00,  3.72464204e+00,\n",
            "        -3.98028183e+00, -1.26908088e+00, -5.79093742e+00,\n",
            "        -1.51382532e+01, -5.39453745e+00,  1.57162800e+01,\n",
            "         1.31184168e+01,  6.09197140e+00, -4.29071331e+00,\n",
            "        -8.85967827e+00, -1.38842478e+01, -1.66156540e+01,\n",
            "        -1.08332863e+01, -1.44471633e+00, -7.57060194e+00,\n",
            "        -1.15761681e+01, -5.71328354e+00,  2.23560143e+00,\n",
            "         9.66318607e+00,  9.91657162e+00,  7.82821369e+00,\n",
            "         8.93953896e+00,  6.25937700e+00, -2.09906387e+00,\n",
            "        -8.57972145e+00, -7.10023403e+00],\n",
            "       [-1.35725937e+01, -1.57019711e+01, -1.25270176e+01,\n",
            "        -4.75145054e+00, -3.45591235e+00, -9.47513008e+00,\n",
            "        -1.38256245e+01, -1.71834793e+01, -2.46633148e+01,\n",
            "        -2.77684708e+01, -1.60826492e+01, -8.63278675e+00,\n",
            "        -4.82617944e-01, -3.99563581e-01, -9.64600682e-01,\n",
            "        -4.88026714e+00, -8.07720947e+00, -8.33418655e+00,\n",
            "        -1.46763134e+00,  1.67967319e+01,  7.29763556e+00,\n",
            "        -5.95099449e+00, -1.29880915e+01, -5.77058172e+00,\n",
            "         3.67450190e+00,  5.01323318e+00,  5.14332867e+00,\n",
            "         2.79565811e+00, -4.28923416e+00, -8.25091171e+00,\n",
            "        -9.38514996e+00, -1.20381861e+01],\n",
            "       [-1.47417915e+00,  1.71812010e+00, -7.28599310e+00,\n",
            "        -8.06721783e+00, -3.68551731e+00, -3.43238616e+00,\n",
            "         6.02867270e+00,  9.18318331e-01, -4.46010768e-01,\n",
            "         5.03862286e+00, -2.57654488e-01,  6.80992222e+00,\n",
            "         1.71367760e+01,  2.09227867e+01,  2.18522053e+01,\n",
            "         2.36109486e+01,  1.23953066e+01, -2.41301346e+00,\n",
            "         2.26026917e+00,  1.61918030e+01,  9.13613510e+00,\n",
            "         1.18077695e+00,  2.43207359e+00,  5.95743752e+00,\n",
            "         1.53789973e+00,  2.82086945e+00,  9.74677467e+00,\n",
            "         1.34648830e-01, -1.03739729e+01, -1.47894402e+01,\n",
            "        -5.39233875e+00, -1.06014991e+00],\n",
            "       [ 6.83140039e+00,  4.65308189e+00,  7.64789581e-02,\n",
            "        -9.25484776e-01, -4.73603678e+00, -1.49720573e+01,\n",
            "        -2.38760281e+01, -1.58615971e+01, -1.93176479e+01,\n",
            "        -2.61981316e+01, -3.35426254e+01, -1.57132759e+01,\n",
            "        -2.20303345e+01, -2.35068512e+01, -1.71040001e+01,\n",
            "        -1.40028019e+01, -1.16207867e+01, -1.16725273e+01,\n",
            "        -1.41885967e+01, -9.40320396e+00, -6.68408442e+00,\n",
            "        -1.01116867e+01, -1.09856691e+01, -1.08260422e+01,\n",
            "        -5.45000935e+00, -6.81406975e-01,  1.88947964e+00,\n",
            "        -6.29877949e+00, -1.14645834e+01, -1.48264198e+01,\n",
            "        -1.83137970e+01, -1.35431213e+01]], dtype=float32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('emotional_command_model.keras')"
      ],
      "metadata": {
        "id": "5zgoK3GNmMA9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir('.'))  # Lista os arquivos no diretório atual"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nyzWnisnmk5",
        "outputId": "bcbb923d-187d-4858-9e22-7ddfb975cec5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'mini_speech_commands', '__MACOSX', 'mini_speech_commands.zip', 'emotional_command_model.keras', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "# Configurações iniciais (mantendo consistência com o código original)\n",
        "COMMANDS = ['down', 'go', 'left', 'no', 'right', 'stop', 'up', 'yes']\n",
        "SAMPLE_RATE = 16000\n",
        "MAX_DURATION = 1\n",
        "\n",
        "def load_audio(file_path, sample_rate, max_duration, fallback_file=None):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Arquivo não encontrado: {file_path}\")\n",
        "        if fallback_file and os.path.exists(fallback_file):\n",
        "            print(f\"Usando arquivo substituto: {fallback_file}\")\n",
        "            file_path = fallback_file\n",
        "        else:\n",
        "            return None\n",
        "    try:\n",
        "        audio, sr = librosa.load(file_path, sr=sample_rate, mono=True, duration=max_duration)\n",
        "        return audio, sr\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar o arquivo {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_emotional_features(file_path):\n",
        "    fallback_files = glob.glob(\"mini_speech_commands/stop/*.wav\")\n",
        "    fallback_file = fallback_files[0] if fallback_files else None\n",
        "    data = load_audio(file_path, SAMPLE_RATE, MAX_DURATION, fallback_file)\n",
        "    if data is None:\n",
        "        return None\n",
        "\n",
        "    audio, sr = data\n",
        "    try:\n",
        "        features = {\n",
        "            'pitch_mean': np.mean(librosa.yin(audio, fmin=100, fmax=800, sr=sr)),\n",
        "            'pitch_std': np.std(librosa.yin(audio, fmin=100, fmax=800, sr=sr)),\n",
        "            'rms_energy': np.mean(librosa.feature.rms(y=audio)[0]),\n",
        "            'zero_crossing_rate': np.mean(librosa.feature.zero_crossing_rate(audio)),\n",
        "            'spectral_centroid': np.mean(librosa.feature.spectral_centroid(y=audio, sr=sr)[0]),\n",
        "            'spectral_bandwidth': np.mean(librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]),\n",
        "            'spectral_rolloff': np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]),\n",
        "            'mfccs': librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "        }\n",
        "        return features\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao extrair características de {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_mel_spectrogram(file_path):\n",
        "    fallback_files = glob.glob(\"mini_speech_commands/stop/*.wav\")\n",
        "    fallback_file = fallback_files[0] if fallback_files else None\n",
        "    data = load_audio(file_path, SAMPLE_RATE, MAX_DURATION, fallback_file)\n",
        "    if data is None:\n",
        "        return None\n",
        "\n",
        "    audio, sr = data\n",
        "    try:\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)\n",
        "        mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "        return mel_spectrogram_db\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao extrair espectrograma de {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_max_dimensions():\n",
        "    \"\"\"\n",
        "    Calcula as dimensões máximas dos espectrogramas no conjunto de dados\n",
        "    \"\"\"\n",
        "    max_rows = 0\n",
        "    max_cols = 0\n",
        "\n",
        "    for command in COMMANDS:\n",
        "        path = f\"mini_speech_commands/{command}\"\n",
        "        if not os.path.exists(path):\n",
        "            continue\n",
        "\n",
        "        for file in glob.glob(os.path.join(path, \"*.wav\")):\n",
        "            spectrogram = extract_mel_spectrogram(file)\n",
        "            if spectrogram is not None:\n",
        "                max_rows = max(max_rows, spectrogram.shape[0])\n",
        "                max_cols = max(max_cols, spectrogram.shape[1])\n",
        "\n",
        "    return max_rows, max_cols\n",
        "\n",
        "def random_file_test(model, num_tests=3):\n",
        "    \"\"\"\n",
        "    Realiza testes com arquivos aleatórios\n",
        "\n",
        "    Args:\n",
        "        model: Modelo treinado\n",
        "        num_tests: Número de testes a realizar\n",
        "    \"\"\"\n",
        "    # Obter dimensões máximas para padding\n",
        "    max_rows, max_cols = get_max_dimensions()\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i in range(num_tests):\n",
        "        print(f\"\\nRealizando teste {i+1}/{num_tests}\")\n",
        "\n",
        "        # Escolher comando aleatório\n",
        "        random_command = random.choice(COMMANDS)\n",
        "        command_path = f\"mini_speech_commands/{random_command}\"\n",
        "\n",
        "        # Selecionar arquivo aleatório\n",
        "        files = glob.glob(os.path.join(command_path, \"*.wav\"))\n",
        "        if not files:\n",
        "            print(f\"Nenhum arquivo encontrado para {random_command}\")\n",
        "            continue\n",
        "\n",
        "        test_file = random.choice(files)\n",
        "        print(f\"Arquivo selecionado: {test_file}\")\n",
        "\n",
        "        # Extrair características\n",
        "        features = extract_emotional_features(test_file)\n",
        "        spectrogram = extract_mel_spectrogram(test_file)\n",
        "\n",
        "        if features is None or spectrogram is None:\n",
        "            print(f\"Falha ao processar {test_file}\")\n",
        "            continue\n",
        "\n",
        "        # Preparar dados para predição\n",
        "        spectrogram = np.pad(\n",
        "            spectrogram,\n",
        "            ((0, max_rows - spectrogram.shape[0]),\n",
        "             (0, max_cols - spectrogram.shape[1])),\n",
        "            mode='constant'\n",
        "        )[np.newaxis,..., np.newaxis]\n",
        "\n",
        "        emotional_features = np.array([\n",
        "            [features['pitch_mean'], features['pitch_std'],\n",
        "             features['rms_energy'], features['zero_crossing_rate']]\n",
        "        ])\n",
        "\n",
        "        # Fazer predição\n",
        "        prediction = model.predict([spectrogram, emotional_features], verbose=0)\n",
        "        predicted_class = COMMANDS[np.argmax(prediction)]\n",
        "        true_class = random_command\n",
        "\n",
        "        # Registrar resultado\n",
        "        result = {\n",
        "            'file': test_file,\n",
        "            'true_class': true_class,\n",
        "            'predicted_class': predicted_class,\n",
        "            'probabilities': dict(zip(COMMANDS, prediction[0].tolist())),\n",
        "            'correct': predicted_class == true_class\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "        # Imprimir resultado do teste\n",
        "        print(f\"\\nResultado do teste {i+1}:\")\n",
        "        print(f\"Classe Verdadeira: {true_class}\")\n",
        "        print(f\"Classe Predita: {predicted_class}\")\n",
        "        print(\"Probabilidades:\")\n",
        "        for cmd, prob in result['probabilities'].items():\n",
        "            print(f\"{cmd}: {prob*100:.2f}%\")\n",
        "        print(f\"Resultado: {'Correto!' if result['correct'] else 'Incorreto.'}\")\n",
        "\n",
        "    # Resumo dos testes\n",
        "    correct_tests = sum(result['correct'] for result in results)\n",
        "    print(f\"\\n=== Resumo dos Testes ===\")\n",
        "    print(f\"Total de Testes: {len(results)}\")\n",
        "    print(f\"Testes Corretos: {correct_tests}\")\n",
        "    print(f\"Precisão: {correct_tests/len(results)*100:.2f}%\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "jXG5zVabmAt1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o modelo e realizar os testes\n",
        "model = tf.keras.models.load_model('emotional_command_model.keras')\n",
        "resultados = random_file_test(model, num_tests=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMA4Nihrqvhn",
        "outputId": "d6685939-21b2-43db-d4e0-584fb86f39d1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Realizando teste 1/5\n",
            "Arquivo selecionado: mini_speech_commands/go/3bfd30e6_nohash_0.wav\n",
            "\n",
            "Resultado do teste 1:\n",
            "Classe Verdadeira: go\n",
            "Classe Predita: go\n",
            "Probabilidades:\n",
            "down: 7.24%\n",
            "go: 62.36%\n",
            "left: 0.00%\n",
            "no: 28.13%\n",
            "right: 2.27%\n",
            "stop: 0.00%\n",
            "up: 0.00%\n",
            "yes: 0.00%\n",
            "Resultado: Correto!\n",
            "\n",
            "Realizando teste 2/5\n",
            "Arquivo selecionado: mini_speech_commands/left/dbaf8fc6_nohash_0.wav\n",
            "\n",
            "Resultado do teste 2:\n",
            "Classe Verdadeira: left\n",
            "Classe Predita: left\n",
            "Probabilidades:\n",
            "down: 0.00%\n",
            "go: 0.00%\n",
            "left: 93.82%\n",
            "no: 0.15%\n",
            "right: 5.34%\n",
            "stop: 0.00%\n",
            "up: 0.27%\n",
            "yes: 0.41%\n",
            "Resultado: Correto!\n",
            "\n",
            "Realizando teste 3/5\n",
            "Arquivo selecionado: mini_speech_commands/left/cb5d2c6e_nohash_1.wav\n",
            "\n",
            "Resultado do teste 3:\n",
            "Classe Verdadeira: left\n",
            "Classe Predita: left\n",
            "Probabilidades:\n",
            "down: 0.00%\n",
            "go: 0.00%\n",
            "left: 95.55%\n",
            "no: 0.66%\n",
            "right: 1.96%\n",
            "stop: 0.00%\n",
            "up: 1.78%\n",
            "yes: 0.05%\n",
            "Resultado: Correto!\n",
            "\n",
            "Realizando teste 4/5\n",
            "Arquivo selecionado: mini_speech_commands/up/f428ca69_nohash_0.wav\n",
            "\n",
            "Resultado do teste 4:\n",
            "Classe Verdadeira: up\n",
            "Classe Predita: up\n",
            "Probabilidades:\n",
            "down: 0.00%\n",
            "go: 0.00%\n",
            "left: 0.00%\n",
            "no: 0.00%\n",
            "right: 0.00%\n",
            "stop: 0.00%\n",
            "up: 100.00%\n",
            "yes: 0.00%\n",
            "Resultado: Correto!\n",
            "\n",
            "Realizando teste 5/5\n",
            "Arquivo selecionado: mini_speech_commands/left/e900b652_nohash_0.wav\n",
            "\n",
            "Resultado do teste 5:\n",
            "Classe Verdadeira: left\n",
            "Classe Predita: left\n",
            "Probabilidades:\n",
            "down: 0.00%\n",
            "go: 0.00%\n",
            "left: 100.00%\n",
            "no: 0.00%\n",
            "right: 0.00%\n",
            "stop: 0.00%\n",
            "up: 0.00%\n",
            "yes: 0.00%\n",
            "Resultado: Correto!\n",
            "\n",
            "=== Resumo dos Testes ===\n",
            "Total de Testes: 5\n",
            "Testes Corretos: 5\n",
            "Precisão: 100.00%\n"
          ]
        }
      ]
    }
  ]
}